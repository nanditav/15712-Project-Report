\section{Introduction}
Deep Neural Networks constitute a state-of-the-art technique across many domains which use machine learning such as autonomous cars, speech recognition, image/video processing, etc. These neural networks however require training over massively large datasets. Hence, training these networks has become notoriously difficult, requiring a significant amount of computational resources to complete in a reasonable amount of time. Traditional formulations of neural networks focus on serialized implementations, which in practice take a very long time to train. In order to overcome this shortcoming a lot of work has focused on parallelizing some aspects of the training phase in order to obtain speedup training. Single node platforms with GPUs have been one of the key ways by which system designers have been able to speed up training. However, a single system cannot be used for large scale training on petabytes of data. It is essential that the training be split up over multiple distributed nodes. This has led to the development of large-scale distributed machine learning frameworks such as TensorFlow~\cite{tensorflow}. 

To test the scalability of distributed training, we performed a number of experiments using TensorFlow to perform the image classification task over the CIFAR-10~\cite{cifar10} dataset. Our experiments show that counterintuitively, scaling out across multiple does not provide the expected speedup in distributed training. A likely reason is the large amount of data that is exchanged over the network to keep the models that are trained in parallel consistent with each other, to ensure convergence. 

In this project, our goal is to accelerate distributed neural network training by leveraging the \emph{approximation-tolerant} nature of these algorithms. It is well known that neural networks are tolerant to towards different approximations that can be leveraged to speed up inference~\cite{x,y}. However, principled approximation in training has been largely limited to techniques that allow different forms of asynchrony between the different workers performing training~\cite{x,y,z}. Our goal in this project is to specifically investigate the hypothesis that different layers in a neural network require different amounts of training to reach convergence, and hence have different tolerance towards approximation. If true, this hypothesis could be leveraged to use different techniques to train, update, and synchronize different layers at different rates or to different extents while retaining model accuracy. Training few layers would significantly reduce the computation time required to compute gradients and transmit updated parameters across the network.  

We evaluate two techniques to test potential differences in the training requirements for different layers: \emph{(i)} Periodic Training Elision: where different layers are trained and updated at different rates, and \emph{(ii)} Selective Early Termination: where training is ended earlier at different points during for some of the layers. 
